{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this\n",
    "from unicodedata import name\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "timelimit = 60\n",
    "\n",
    "index_template = [\"sat\", \"unsat\", \"unknown\", \"error\", \"timeout\", \"time(ms)\"]\n",
    "\n",
    "\n",
    "class ResultDic:\n",
    "    name: str\n",
    "    resdic: dict\n",
    "\n",
    "    def __init__(self, name: str) -> None:\n",
    "        self.name = name\n",
    "        self.resdic = {}\n",
    "\n",
    "    def update(self, colname: str, onedata: list):\n",
    "        self.resdic[colname] = onedata\n",
    "\n",
    "    def isempty(self):\n",
    "        return self.resdic == {}\n",
    "\n",
    "\n",
    "class ResultDf:\n",
    "    resdics: dict[str, ResultDic]\n",
    "\n",
    "    def __init__(self, resultfiles: list[str]) -> None:\n",
    "        self.resdics = {file: ResultDic(file) for file in resultfiles}\n",
    "\n",
    "    def update(self, backend: str, colname: str, onedata: list):\n",
    "        \"\"\"update result dataframe for a backend\n",
    "\n",
    "        Args:\n",
    "            backend (str): name of backend\n",
    "            colname (str): name of column\n",
    "            onedata (list): one column data\n",
    "        \"\"\"\n",
    "        self.resdics[backend].update(colname, onedata)\n",
    "\n",
    "    def get_df(self) -> list[DataFrame]:\n",
    "        \"\"\"convert to dataframe\n",
    "\n",
    "        Returns:\n",
    "            res (list[Dataframe]): generator of dataframe\n",
    "        \"\"\"\n",
    "        df_list = []\n",
    "        for resdic in self.resdics.values():\n",
    "            if resdic.isempty():\n",
    "                print(f\"Warning: {resdic.name} is empty\")\n",
    "                continue\n",
    "            res = DataFrame(resdic.resdic, index=index_template).astype(\"int64\").T\n",
    "            res.name = resdic.name\n",
    "            df_list.append(res)\n",
    "        return df_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Get files containing the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hudh/github/ostrich/experiment/res/23-02-08_14:34:02z3str3re_output/z3str3re_log.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "commit = '23-02-08_14:34:02z3str3re_output'\n",
    "\n",
    "dirname = os.path.abspath(\"\")\n",
    "\n",
    "analyzed_files = glob.glob(f\"{dirname}/res/{commit}/*_log.txt\", recursive=True)\n",
    "print(analyzed_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z3str3re_log.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat</th>\n",
       "      <td>24109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsat</th>\n",
       "      <td>14463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeout</th>\n",
       "      <td>1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time(sat) ms</th>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time(unsat) ms</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time(total) ms</th>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z3str3re_log.txt\n",
       "sat                            24109\n",
       "unsat                          14463\n",
       "unknown                            0\n",
       "error                              0\n",
       "timeout                         1934\n",
       "avg_time(sat) ms                 214\n",
       "avg_time(unsat) ms                 8\n",
       "avg_time(total) ms              2999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parse_single_result(result: str) -> list[int | float]:\n",
    "    SAT_RE = re.compile(\"^sat\", re.M)\n",
    "    UNSAT_RE = re.compile(\"^unsat\", re.M)\n",
    "    UNKNOWN_RE = re.compile(\"^unknown|^--Unknown\", re.M)\n",
    "    ERR_RE = re.compile(\"^\\(error |^--Exception\", re.M | re.I)\n",
    "    TIMEOUT_RE = re.compile(\"^Timeout\", re.M)\n",
    "    TIME_RE = re.compile(\"^Time: (.*)ms\", re.M)\n",
    "    sat = unsat = timeout = unknown = err = timeused = 0\n",
    "    if SAT_RE.search(result):\n",
    "        sat = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    elif UNSAT_RE.search(result):\n",
    "        unsat = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    elif UNKNOWN_RE.search(result):\n",
    "        unknown = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    elif TIMEOUT_RE.search(result):\n",
    "        timeout = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    elif ERR_RE.search(result):\n",
    "        # else:\n",
    "        err = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    onedata = [sat, unsat, unknown, err, timeout, timeused]\n",
    "    return onedata\n",
    "\n",
    "\n",
    "def parse_files(filenames: list[str]) -> ResultDf:\n",
    "    \"\"\"parse a file to get data\n",
    "\n",
    "    Args:\n",
    "        filename (str): file name\n",
    "\n",
    "    Returns:\n",
    "        ResultDf: result dataframe\n",
    "    \"\"\"\n",
    "    basenames = [os.path.basename(filename) for filename in filenames]\n",
    "    res = ResultDf(basenames)\n",
    "    for filename in filenames:\n",
    "        # backend = re.search(f\"([a-z]+)_log.txt\", filename).group(1)\n",
    "        backend = os.path.basename(filename)\n",
    "        INSTANCE_RE = re.compile(\"^Running \\[(.*)\\]\", re.M)\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.read()\n",
    "            results = lines.split(\"----splitter----\")\n",
    "            for result in results[:-1]:\n",
    "                instance = INSTANCE_RE.search(result).group(1)\n",
    "                onedata = parse_single_result(result)\n",
    "                res.update(backend, instance, onedata)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = parse_files(analyzed_files)\n",
    "\n",
    "\n",
    "def get_final_df(res: ResultDf):\n",
    "    \"\"\"get final dataframe\n",
    "\n",
    "    Args:\n",
    "        res (ResultDf): result dataframe\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: final dataframe\n",
    "    \"\"\"\n",
    "    dataframes: list[DataFrame] = []\n",
    "    for df in res.get_df():\n",
    "        dic = {}\n",
    "        dic[\"avg_time(sat) ms\"] = [df[df[\"sat\"] == 1][\"time(ms)\"].mean()]\n",
    "        dic[\"avg_time(unsat) ms\"] = [df[df[\"unsat\"] == 1][\"time(ms)\"].mean()]\n",
    "        dic[\"avg_time(total) ms\"] = [df[\"time(ms)\"].mean()]\n",
    "        avgf = DataFrame(dic).T.fillna(0)\n",
    "        sumf = df.sum().drop(index=\"time(ms)\")\n",
    "        concatf = pd.concat([sumf, avgf]).astype(\"int64\")\n",
    "        concatf.name = df.name\n",
    "        dataframes.append(concatf)\n",
    "\n",
    "    index = [i for i in range(len(dataframes))]\n",
    "    dfnames = [df.name for df in dataframes]\n",
    "    resdf = pd.concat(dataframes, axis=1, ignore_index=True).rename(\n",
    "        columns=dict(zip(index, dfnames))\n",
    "    )\n",
    "    return resdf\n",
    "\n",
    "\n",
    "get_final_df(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5b8875d39a1c338d63caacf6743fab6c08e73a619ca589b0b737f993fdbd9c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

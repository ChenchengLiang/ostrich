{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this\n",
    "from unicodedata import name\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "timelimit = 60\n",
    "\n",
    "index_template = [\"sat\", \"unsat\", \"unknown\", \"error\", \"timeout\", \"time(ms)\"]\n",
    "\n",
    "\n",
    "class ResultDic:\n",
    "    name: str\n",
    "    resdic: dict\n",
    "\n",
    "    def __init__(self, name: str) -> None:\n",
    "        self.name = name\n",
    "        self.resdic = {}\n",
    "\n",
    "    def update(self, colname: str, onedata: list):\n",
    "        self.resdic[colname] = onedata\n",
    "\n",
    "    def isempty(self):\n",
    "        return self.resdic == {}\n",
    "\n",
    "\n",
    "class ResultDf:\n",
    "    resdics: dict[str, ResultDic]\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.resdics = {\n",
    "            \"unary\": ResultDic(\"unary\"),\n",
    "            \"catra\": ResultDic(\"catra\"),\n",
    "            \"baseline\": ResultDic(\"baseline\")\n",
    "        }\n",
    "\n",
    "    def update(self, backend: str, colname: str, onedata: list):\n",
    "        \"\"\"update result dataframe for a backend\n",
    "\n",
    "        Args:\n",
    "            backend (str): name of backend\n",
    "            colname (str): name of column\n",
    "            onedata (list): one column data\n",
    "        \"\"\"\n",
    "        self.resdics[backend].update(colname, onedata)\n",
    "\n",
    "    def get_df(self) -> list[DataFrame]:\n",
    "        \"\"\"convert to dataframe\n",
    "\n",
    "        Returns:\n",
    "            res (list[Dataframe]): generator of dataframe\n",
    "        \"\"\"\n",
    "        df_list = []\n",
    "        for resdic in self.resdics.values():\n",
    "            if resdic.isempty():\n",
    "                print(f\"Warning: {resdic.name} is empty\")\n",
    "                continue\n",
    "            res = DataFrame(resdic.resdic, index=index_template).astype(\"int64\").T\n",
    "            res.name = resdic.name\n",
    "            df_list.append(res)\n",
    "        return df_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Get files containing the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hudh/github/ostrich/experiment/res/22-11-02_22:56:47totaltime/unary_log.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "commit = '22-11-02_22:56:47totaltime'\n",
    "\n",
    "dirname = os.path.abspath(\"\")\n",
    "\n",
    "analyzed_files = glob.glob(f\"{dirname}/res/{commit}/*_log.txt\", recursive=True)\n",
    "print(analyzed_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: catra is empty\n",
      "Warning: baseline is empty\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat</th>\n",
       "      <td>27185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsat</th>\n",
       "      <td>20567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>7440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeout</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time(sat) ms</th>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time(unsat) ms</th>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time(total) ms</th>\n",
       "      <td>5900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    unary\n",
       "sat                 27185\n",
       "unsat               20567\n",
       "unknown              1150\n",
       "error                7440\n",
       "timeout               354\n",
       "avg_time(sat) ms     1230\n",
       "avg_time(unsat) ms   1102\n",
       "avg_time(total) ms   5900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_single_result(result: str) -> list[int|float]:\n",
    "    SAT_RE = re.compile(\"^sat\", re.M)\n",
    "    UNSAT_RE = re.compile(\"^unsat\", re.M)\n",
    "    UNKNOWN_RE = re.compile(\"^unknown|^--Unknown\", re.M)\n",
    "    ERR_RE = re.compile(\"^\\(error |^--Exception\", re.M | re.I)\n",
    "    TIMEOUT_RE = re.compile(\"^Timeout\", re.M)\n",
    "    TIME_RE = re.compile(\"^Time: (.*)ms\", re.M)\n",
    "    sat = unsat = timeout = unknown = err = timeused = 0\n",
    "    if SAT_RE.search(result):\n",
    "        sat = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    elif UNSAT_RE.search(result):\n",
    "        unsat = 1\n",
    "        timeused = float(TIME_RE.search(result).group(1))\n",
    "    elif UNKNOWN_RE.search(result):\n",
    "        unknown = 1\n",
    "        timeused = float(timelimit * 500)\n",
    "    elif TIMEOUT_RE.search(result):\n",
    "        timeout = 1\n",
    "        timeused = float(timelimit * 1000)\n",
    "    elif ERR_RE.search(result):\n",
    "    # else:\n",
    "        err = 1\n",
    "        timeused = float(timelimit* 500)\n",
    "    onedata = [sat, unsat, unknown, err, timeout, timeused]\n",
    "    return onedata\n",
    "\n",
    "def parse_files(filenames: list[str]) -> ResultDf:\n",
    "    \"\"\"parse a file to get data\n",
    "\n",
    "    Args:\n",
    "        filename (str): file name\n",
    "\n",
    "    Returns:\n",
    "        ResultDf: result dataframe\n",
    "    \"\"\"\n",
    "    res = ResultDf()\n",
    "    for filename in filenames:\n",
    "        backend = re.search(f\"([a-z]+)_log.txt\", filename).group(1)\n",
    "        INSTANCE_RE = re.compile(\"^Running \\[(.*)\\]\", re.M)\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.read()\n",
    "            results = lines.split(\"----splitter----\")\n",
    "            for result in results[:-1]:\n",
    "                instance = INSTANCE_RE.search(result).group(1)\n",
    "                onedata = parse_single_result(result)\n",
    "                res.update(backend, instance, onedata)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = parse_files(analyzed_files)\n",
    "\n",
    "\n",
    "def get_final_df(res: ResultDf):\n",
    "    \"\"\"get final dataframe\n",
    "\n",
    "    Args:\n",
    "        res (ResultDf): result dataframe\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: final dataframe\n",
    "    \"\"\"\n",
    "    dataframes: list[DataFrame] = []\n",
    "    for df in res.get_df():\n",
    "        dic = {}\n",
    "        dic[\"avg_time(sat) ms\"] = [df[df[\"sat\"] == 1][\"time(ms)\"].mean()]\n",
    "        dic[\"avg_time(unsat) ms\"] = [df[df[\"unsat\"] == 1][\"time(ms)\"].mean()]\n",
    "        dic[\"avg_time(total) ms\"] = [df[\"time(ms)\"].mean()]\n",
    "        avgf = DataFrame(dic).T\n",
    "        sumf = df.sum().drop(index=\"time(ms)\")\n",
    "        concatf = pd.concat([sumf, avgf]).astype(\"int64\")\n",
    "        concatf.name = df.name\n",
    "        dataframes.append(concatf)\n",
    "\n",
    "    index = [i for i in range(len(dataframes))]\n",
    "    dfnames = [df.name for df in dataframes]\n",
    "    resdf = pd.concat(dataframes, axis=1, ignore_index=True).rename(\n",
    "        columns=dict(zip(index, dfnames))\n",
    "    )\n",
    "    return resdf\n",
    "\n",
    "\n",
    "get_final_df(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5b8875d39a1c338d63caacf6743fab6c08e73a619ca589b0b737f993fdbd9c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
